1.Hadoop的两点核心价值HDFS和MapReduce


2.jobtracker崩了怎么办


3.合理的分片大小趋向于HDFS的一个块的大小，默认是64MB，不过可以针对集群调整这个默认值（对新建的所有文件），或对新建的每个文件具体制定。最佳分片的大小应该与块大小相同，因为它是确保可以存储在单个节点上的最大输入块的大小。


4.HDFS是为了处理大型数据集分析任务的，主要是为达到高的数据吞吐量而设计的，这就可能要求以高延迟作为代价。对于那些有低延时要求的应用程序，HBase是一个更好的选择。通过上层数据管理项目来尽可能地弥补这个不足。在性能上有了很大的提升，它的口号就是goes real time。使用缓存或多master设计可以降低client的数据请求压力，以减少延时。还有就是对HDFS系统内部的修改，这就得权衡大吞吐量与低延时了。


5.map任务将其输出写入本地磁盘，因为map的输出是中间结果。reduce任务的输入通常来自于所有mapper的输出，排过序的map输出通过网络传输发送到运行reduce任务的节点，数据在reduce端合并，然后由用户定义的reduce函数处理。reduce的输出通常存储在HDFS中以实现可靠存储。


6.block物理上划分。split逻辑上划分，一个split有多少个block可以计算。


7.HDFS的构建思路是：一次写入/多次读取是最高效的访问模式。数据集通常由数据源复制而来，接着长时间在此数据集上进行各种分析。每次分析都将涉及该数据集的大部分甚至全部，因此读取整个数据集的时间延迟比读取第一条记录的时间延迟更重要。


8.磁盘块一般为512字节。
HDFS中也有块的概念，默认为64MB，很多情况下HDFS使用128MB的块设置，随着磁盘驱动器传输速率的提升，块的大小将被设置得更大。（HDFS的块比磁盘的块大，其目的是为了最小化寻址开销，如果块设置得足够大，从磁盘传输数据的时间会明显大于定位这个块开始位置所需的时间）
